import streamlit as st
from datetime import datetime
from streamlit_webrtc import webrtc_streamer, WebRtcMode

# Import functions from your other files
from utils import get_openai_key, extract_text, text_to_speech, autoplay_audio, transcribe_audio
from core_ai_logic import generate_questions, evaluate_answer, summarize_session
from pdf_generator import generate_pdf

# Constants that this file needs
MODELS = {"GPT-4o": "gpt-4o", "GPT-4": "gpt-4", "GPT-3.5": "gpt-3.5-turbo"}
RTC_CONFIGURATION = {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}

# --- UI Functions ---
def sidebar(authenticator):
    st.sidebar.markdown(f"Welcome *{st.session_state['name']}*")
    authenticator.logout('Logout', 'sidebar', key='logout_button')
    st.sidebar.markdown("---")
    st.sidebar.markdown("### Interview Settings")
    st.session_state["openai_api_key"] = st.sidebar.text_input("OpenAI API Key", type="password", placeholder="Paste key here")

def setup_section(authenticator, config):
    st.header("Step 1: Resume and Candidate Details")
    name = st.text_input("Candidate Name", value=st.session_state.get('name', ''))
    role = st.text_input("Position / Role", "Software Engineer")
    q_count = st.slider("Number of Questions", 3, 10, 5)
    
    uploaded_file = st.file_uploader("Upload candidate's resume (PDF or TXT)", type=["pdf", "txt"])
    if uploaded_file:
        resume = extract_text(uploaded_file)
        st.text_area("Resume Preview", resume, height=150)
        
        if st.button("Start Interview", type="primary"):
            if resume and name and get_openai_key():
                st.session_state.update({"resume": resume, "candidate_name": name, "role": role, "q_count": q_count, "answers": [], "current_q": 0, "stage": "interview"})
                with st.spinner("Generating personalized questions..."):
                    st.session_state.questions = generate_questions(resume, role, "Mid-Level", q_count, MODELS["GPT-4o"])
                st.rerun()
            else:
                st.warning("Please ensure all fields are complete and an API key is provided.")

def interview_section(authenticator, config, InterviewProcessor):
    idx = st.session_state.current_q
    questions = st.session_state.get("questions", [])
    if not questions or idx >= len(questions):
        st.session_state.stage = "summary"; st.rerun()

    q = questions[idx]
    st.header(f"Question {idx+1}/{len(questions)}: {q['topic']} ({q['difficulty']})"); st.subheader(q['text'])

    if f"tts_{idx}" not in st.session_state:
        with st.spinner("Generating audio..."):
            audio_response = text_to_speech(q['text'])
            st.session_state[f"tts_{idx}"] = audio_response.content if audio_response else None
    if st.session_state[f"tts_{idx}"]:
        autoplay_audio(st.session_state[f"tts_{idx}"])

    st.markdown("---")
    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("#### Candidate Live Feed")
        if "audio_buffer" not in st.session_state: st.session_state.audio_buffer = []
        if "proctoring_img" not in st.session_state: st.session_state.proctoring_img = None
        
        webrtc_ctx = webrtc_streamer(key=f"interview_cam_{idx}", mode=WebRtcMode.SENDRECV, rtc_configuration=RTC_CONFIGURATION, media_stream_constraints={"video": True, "audio": True}, processor_factory=InterviewProcessor, async_processing=True)
        
        if webrtc_ctx.state.playing and webrtc_ctx.processor:
            st.session_state.audio_buffer.extend(webrtc_ctx.processor.audio_buffer)
            webrtc_ctx.processor.audio_buffer.clear()

    with col2:
        st.markdown("#### Proctoring Snapshot")
        if st.session_state.proctoring_img:
            st.image(st.session_state.proctoring_img, caption=f"Snapshot at {datetime.now().strftime('%H:%M:%S')}")
        else:
            st.info("Waiting for first candidate snapshot...")

    st.markdown("---")
    if st.button("Stop and Submit Answer", type="primary"):
        if webrtc_ctx.state.playing and hasattr(webrtc_ctx, 'processor') and webrtc_ctx.processor:
            st.session_state.audio_buffer.extend(webrtc_ctx.processor.audio_buffer)
        
        if not st.session_state.audio_buffer:
            st.warning("Please record an answer before submitting."); return
        
        full_audio_bytes = b"".join(st.session_state.audio_buffer)
        st.session_state.audio_buffer = []
        
        with st.spinner("Transcribing and evaluating your answer..."):
            answer_text = transcribe_audio(full_audio_bytes)
            if answer_text:
                st.info(f"**Transcribed Answer:** {answer_text}")
                evaluation = evaluate_answer(q, answer_text, st.session_state.get('resume'), MODELS["GPT-4o"])
                evaluation["answer"] = answer_text
                st.session_state.answers.append(evaluation)
                st.session_state.current_q += 1
                st.session_state.proctoring_img = None
                st.rerun()
            else:
                st.error("Transcription failed. Please try recording your answer again.")

def summary_section(authenticator, config):
    st.header("Step 3: Interview Summary")
    with st.spinner("Generating final summary..."):
        summary = summarize_session(st.session_state.questions, st.session_state.answers, st.session_state.resume, MODELS["GPT-4o"])
    st.subheader(f"Overall Score: {summary.get('overall_score', '-')}/10"); st.markdown(f"**Recommendation:** {summary.get('recommendation', '')}")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**Strengths:**"); [st.write(f"- {s}") for s in summary.get("strengths", [])]
    with col2:
        st.markdown("**Weaknesses:**"); [st.write(f"- {w}") for w in summary.get("weaknesses", [])]
    pdf_buffer = generate_pdf(st.session_state.candidate_name, st.session_state.role, summary, st.session_state.questions, st.session_state.answers)
    st.download_button("Download PDF Report", pdf_buffer, f"{st.session_state.candidate_name}_Report.pdf", type="primary")
    if st.button("Start New Interview"):
        keys_to_clear = [k for k in st.session_state.keys() if k not in ['authentication_status', 'name', 'username']]
        for key in keys_to_clear:
            del st.session_state[key]
        st.rerun()
